<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Reinforcement Learning &amp; The Rate Limit Bottleneck | FileSense</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Reinforcement Learning &amp; The Rate Limit Bottleneck" />
<meta property="og:locale" content="en_US" />
<meta property="og:site_name" content="FileSense" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Reinforcement Learning &amp; The Rate Limit Bottleneck" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"Reinforcement Learning &amp; The Rate Limit Bottleneck","url":"/RL.html"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=ff113580487d33068b3216f649af5514f0da9c75">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <div class="container-lg px-3 my-5 markdown-body">
      
      <h1><a href="/">FileSense</a></h1>
      

      <h1 id="reinforcement-learning--the-rate-limit-bottleneck">Reinforcement Learning &amp; The Rate Limit Bottleneck</h1>

<h2 id="-critical-analysis-why-the-api-approach-failed">üö® Critical Analysis: Why the API Approach Failed</h2>

<h3 id="1-the-bottleneck-api-quotas--latency">1. The Bottleneck: API Quotas &amp; Latency</h3>
<p>Despite implementing an intelligent RL agent (Epsilon-Greedy Bandit) to minimize API calls (Policy C), the dependency on Google Gemini‚Äôs API proved fatal for the project‚Äôs scalability.</p>

<p><strong>Evidence from Logs (<code class="language-plaintext highlighter-rouge">RL_init.log</code>, <code class="language-plaintext highlighter-rouge">RL_RATE_LIMIT_RAGEBAIT.log</code>):</strong></p>
<ul>
  <li><strong>Severe Rate Limiting (429 RESOURCE_EXHAUSTED):</strong>
    <blockquote>
      <p><code class="language-plaintext highlighter-rouge">Error: 429 RESOURCE_EXHAUSTED ... limit: 20 requests/day ... Please retry in 43.82s</code>
The free/standard tier limits are far too low for a file organizer that might process hundreds of files. A limit of ~20 requests forces the system to sleep more than it works.</p>
    </blockquote>
  </li>
  <li><strong>Service Unavailability (503 UNAVAILABLE):</strong>
    <blockquote>
      <p><code class="language-plaintext highlighter-rouge">Error: 503 UNAVAILABLE ... The model is overloaded.</code>
Even within the quota, the model frequently failed to respond, triggering retry loops that added 10-20 seconds of delay per file.</p>
    </blockquote>
  </li>
  <li><strong>Unacceptable Latency:</strong>
The retry logic and backoff strategies blew up processing times:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">file_005.txt</code>: <strong>57.45s</strong></li>
      <li><code class="language-plaintext highlighter-rouge">file_003.txt</code>: <strong>70.12s</strong></li>
      <li><code class="language-plaintext highlighter-rouge">file_004.txt</code>: <strong>96.77s</strong></li>
      <li><code class="language-plaintext highlighter-rouge">file_007.txt</code>: <strong>123.44s</strong></li>
    </ul>

    <p><em>Compare this to Vector Search (Policy C):</em> <code class="language-plaintext highlighter-rouge">~0.50s</code> per file.</p>
  </li>
</ul>

<h3 id="2-failure-of-the-rl-fix">2. Failure of the RL ‚ÄúFix‚Äù</h3>
<p>The RL agent correctly identified <strong>Policy C (No GenAI)</strong> as the optimal policy because it had the highest reward (speed + no errors). However, when the system <em>did</em> need to generate a new label (Exploration or Low Confidence), the API failure broke the entire loop.</p>

<ul>
  <li><strong>The ‚ÄúGap‚Äù:</strong> We cannot rely on the API even for the 10% ‚ÄúExplore‚Äù cases without risking a 60-second freeze.</li>
  <li><strong>Manual Fallback:</strong> The logs show the system constantly asking the user for manual input (<code class="language-plaintext highlighter-rouge">Please manually input the folder label</code>), essentially defeating the purpose of an <em>automatic</em> organizer.</li>
</ul>

<hr />

<h2 id="-strategic-shift-supervised-fine-tuning-sft">üõë Strategic Shift: Supervised Fine-Tuning (SFT)</h2>

<p><strong>Problem:</strong> We need the intelligence of an LLM to generate labels for unknown files, but we cannot afford the latency or rate limits of an API.
<strong>Solution:</strong> <strong>Supervised Fine-Tuning (SFT)</strong> a local Small Language Model (SLM).</p>

<h3 id="why-sft">Why SFT?</h3>
<ol>
  <li><strong>Zero Latency:</strong> A local model (e.g., Llama-3-8B-Quantized or TinyLlama) running on the GPU/CPU has no network overhead.</li>
  <li><strong>No Rate Limits:</strong> We can classify 10,000 files in a row without asking permission or waiting for quotas.</li>
  <li><strong>Privacy:</strong> File contents never leave the user‚Äôs machine.</li>
</ol>

<h3 id="the-plan">The Plan</h3>
<ol>
  <li><strong>Data Collection:</strong> We have collected high-quality ‚ÄúEvent‚Äù data in <code class="language-plaintext highlighter-rouge">rl_events.jsonl</code> (Input Text -&gt; Predicted Label).</li>
  <li><strong>Dataset Creation:</strong> Format these events into an SFT dataset (Instruction Tuning format).
    <ul>
      <li><em>Input:</em> ‚ÄúClassify this text: {content_summary}‚Äù</li>
      <li><em>Output:</em> ‚Äú{label}‚Äù</li>
    </ul>
  </li>
  <li><strong>Fine-Tuning:</strong> Train a small, efficient model to replicate the decision-making of the larger Gemini model.</li>
  <li><strong>Deployment:</strong> Replace the <code class="language-plaintext highlighter-rouge">generate_label.py</code> API calls with a local inference function.</li>
</ol>

<hr />

<h2 id="-original-architecture-reference">üìú Original Architecture (Reference)</h2>

<h3 id="strategy-epsilon-greedy-bandit">Strategy: Epsilon-Greedy Bandit</h3>
<ul>
  <li><strong>Action:</strong> Choose a Policy (A, B, or C).</li>
  <li><strong>Reward:</strong> 1 (Success/Correct Sort) or 0 (Failure/Manual Fix).</li>
  <li><strong>Goal:</strong> Maximize cumulative reward over time.</li>
</ul>

<h3 id="policies">Policies</h3>
<p>| Policy | Threshold | Allow GenAI? | Description |
|:‚Äî:|:‚Äî:|:‚Äî:|‚Äî|
| <strong>A</strong> | 0.45 | <strong>Yes</strong> | Conservative. High overlap required. |
| <strong>B</strong> | 0.40 | <strong>Yes</strong> | Balanced. |
| <strong>C</strong> | 0.35 | <strong>No</strong>  | <strong>Efficient.</strong> Aggressive matching. Pure Vector Search. |</p>

<p><em>(Note: While logical, this architecture is currently paused in favor of the SFT migration.)</em></p>


      
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js" integrity="sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=" crossorigin="anonymous"></script>
    <script>anchors.add();</script>
  </body>
</html>
